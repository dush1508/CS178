{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t1vZcI4ip8SM",
        "outputId": "e4be2137-36a6-42ae-ae75-89a801acd5fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for toxic...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31914' max='31914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31914/31914 15:39, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.043400</td>\n",
              "      <td>0.152917</td>\n",
              "      <td>0.957512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.135832</td>\n",
              "      <td>0.963747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for toxic:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     28856\n",
            "           1       0.87      0.74      0.80      3059\n",
            "\n",
            "    accuracy                           0.96     31915\n",
            "   macro avg       0.92      0.86      0.89     31915\n",
            "weighted avg       0.96      0.96      0.96     31915\n",
            "\n",
            "\n",
            "Training model for severe_toxic...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31914' max='31914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31914/31914 15:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.071700</td>\n",
              "      <td>0.062211</td>\n",
              "      <td>0.990005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.019700</td>\n",
              "      <td>0.034967</td>\n",
              "      <td>0.990005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for severe_toxic:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     31596\n",
            "           1       0.00      0.00      0.00       319\n",
            "\n",
            "    accuracy                           0.99     31915\n",
            "   macro avg       0.50      0.50      0.50     31915\n",
            "weighted avg       0.98      0.99      0.99     31915\n",
            "\n",
            "\n",
            "Training model for obscene...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31914' max='31914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31914/31914 15:58, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.021500</td>\n",
              "      <td>0.080077</td>\n",
              "      <td>0.979414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.024100</td>\n",
              "      <td>0.063147</td>\n",
              "      <td>0.981419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for obscene:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     30225\n",
            "           1       0.84      0.80      0.82      1690\n",
            "\n",
            "    accuracy                           0.98     31915\n",
            "   macro avg       0.91      0.90      0.91     31915\n",
            "weighted avg       0.98      0.98      0.98     31915\n",
            "\n",
            "\n",
            "Training model for threat...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31914' max='31914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31914/31914 15:47, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.021837</td>\n",
              "      <td>0.996992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.071900</td>\n",
              "      <td>0.015746</td>\n",
              "      <td>0.996992</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for threat:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     31819\n",
            "           1       0.00      0.00      0.00        96\n",
            "\n",
            "    accuracy                           1.00     31915\n",
            "   macro avg       0.50      0.50      0.50     31915\n",
            "weighted avg       0.99      1.00      1.00     31915\n",
            "\n",
            "\n",
            "Training model for insult...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31914' max='31914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31914/31914 15:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.139120</td>\n",
              "      <td>0.963779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.127778</td>\n",
              "      <td>0.964092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for insult:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     30340\n",
            "           1       0.65      0.58      0.61      1575\n",
            "\n",
            "    accuracy                           0.96     31915\n",
            "   macro avg       0.82      0.78      0.80     31915\n",
            "weighted avg       0.96      0.96      0.96     31915\n",
            "\n",
            "\n",
            "Training model for identity_hate...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31914' max='31914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31914/31914 15:55, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.161000</td>\n",
              "      <td>0.053027</td>\n",
              "      <td>0.991195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.039191</td>\n",
              "      <td>0.991634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for identity_hate:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00     31634\n",
            "           1       0.59      0.16      0.25       281\n",
            "\n",
            "    accuracy                           0.99     31915\n",
            "   macro avg       0.79      0.58      0.62     31915\n",
            "weighted avg       0.99      0.99      0.99     31915\n",
            "\n",
            "\n",
            "Summary of Precision Scores:\n",
            "toxic: Precision = 0.8663\n",
            "severe_toxic: Precision = 0.0000\n",
            "obscene: Precision = 0.8388\n",
            "threat: Precision = 0.0000\n",
            "insult: Precision = 0.6535\n",
            "identity_hate: Precision = 0.5946\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "import warnings\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import EarlyStoppingCallback\n",
        "import numpy as np\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text_v2(text):\n",
        "    if pd.isnull(text):\n",
        "        return '<empty>'\n",
        "    text = re.sub(r'[^\\w\\s!@#$%^&*]', '', text.lower())\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_comment_text'] = df['comment_text'].apply(clean_text_v2)\n",
        "\n",
        "# Load tokenizer and model (using ALBERT, a smaller model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\", use_fast=True)\n",
        "\n",
        "Label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "results = {}\n",
        "\n",
        "# Tokenizer function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding=\"max_length\", truncation=True, max_length=128)  # Reduce max length\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop\n",
        "for label in Label_columns:\n",
        "    print(f\"\\nTraining model for {label}...\\n\")\n",
        "\n",
        "    y = df[label]\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['cleaned_comment_text'], y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Tokenize data with padding and truncation to max length\n",
        "    train_encodings = tokenizer(list(X_train), padding=True, truncation=True, max_length=128)\n",
        "    test_encodings = tokenizer(list(X_test), padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    class ToxicDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n",
        "            item['labels'] = torch.tensor(self.labels[idx]).to(device)\n",
        "            return item\n",
        "\n",
        "    train_dataset = ToxicDataset(train_encodings, y_train.values)\n",
        "    test_dataset = ToxicDataset(test_encodings, y_test.values)\n",
        "\n",
        "    # Load model (using ALBERT)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "    #model = model.to(device)  # Move model to GPU if available\n",
        "\n",
        "    # Define training arguments with optimizations\n",
        "    training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",  # Output directory\n",
        "    evaluation_strategy=\"epoch\",  # Disable evaluation during training\n",
        "    save_strategy=\"epoch\",  # Save every epoch\n",
        "    learning_rate=5e-5,  # Learning rate\n",
        "    per_device_train_batch_size=8,  # Batch size for training\n",
        "    per_device_eval_batch_size=16,  # Batch size for evaluation\n",
        "    num_train_epochs=2,  # Fewer epochs to speed up\n",
        "    weight_decay=0.01,  # Weight decay\n",
        "    logging_dir=\"./logs\",  # Directory for logs\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,  # Load the best model based on evaluation metrics\n",
        "    metric_for_best_model=\"accuracy\",  # Metric to track\n",
        "    fp16=True,  # Enable mixed precision training for GPU acceleration\n",
        "    gradient_checkpointing=False,  # Reduce memory usage during training\n",
        "    report_to=\"none\",  # Disable WandB\n",
        "    dataloader_pin_memory=False,\n",
        "    )\n",
        "\n",
        "    # EarlyStoppingCallback with a lower patience\n",
        "    early_stopping_callback = EarlyStoppingCallback(\n",
        "        early_stopping_patience=1)  # Stop after 1 step of no improvement\n",
        "\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    # Define a function to compute evaluation metrics, including accuracy\n",
        "    def compute_metrics(p):\n",
        "      predictions, labels = p\n",
        "      preds = predictions.argmax(axis=-1)  # Get the predicted class labels\n",
        "      accuracy = accuracy_score(labels, preds)  # Calculate accuracy\n",
        "      return {'eval_accuracy': accuracy}  # Return the accuracy in the dictionary\n",
        "\n",
        "    # Trainer setup\n",
        "    trainer = Trainer(\n",
        "    model=model.to(device),  # Ensure the model is moved to the correct device (GPU)\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    callbacks=[early_stopping_callback],  # Add early stopping callback\n",
        "    compute_metrics=compute_metrics,  # Pass the compute_metrics function\n",
        "    )\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the model\n",
        "    model.save_pretrained(f\"./saved_model_{label}\")\n",
        "    tokenizer.save_pretrained(f\"./saved_model_{label}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    preds = np.argmax(predictions.predictions, axis=1)\n",
        "    report = classification_report(y_test, preds, output_dict=True)\n",
        "    results[label] = report\n",
        "\n",
        "    print(f\"Classification Report for {label}:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "print(\"\\nSummary of Precision Scores:\")\n",
        "for label, report in results.items():\n",
        "    print(f\"{label}: Precision = {report['1']['precision']:.4f}\")\n",
        "\n",
        "# Save results to CSV\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df.to_csv('classification_reports_pretrained.csv', index=True)\n"
      ]
    }
  ]
}